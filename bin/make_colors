#!/usr/bin/env python

import os
import os.path as osp
import json
import click
import torch
import h5py
from skimage import io
import pickle
from tqdm import tqdm
from bvpr.data.corpus import Corpus
from bvpr.data.colorization import PAD_TOKEN, UNK_TOKEN

def create_records(f, split, i2w):
    data = f[f"{split}_words"]
    num_examples = data.shape[0]
    records = list()
    for i in tqdm(range(num_examples)):
        tokens = [i2w[t] for t in data[i] if t != 0]
        caption = " ".join(tokens)
        image_file = f"{split}_{i:05d}.jpg"
        example_id = i

        records.append({
            "image_file": image_file,
            "example_id": example_id,
            "caption": caption,
            "split": split,
        })
    return records


def write_images(f, split, images_dir):
    data = f[f"{split}_ims"]
    num_examples = data.shape[0]
    for i in tqdm(range(num_examples)):
        image_file = f"{split}_{i:05d}.jpg"
        image_path = osp.join(images_dir, image_file)
        image = data[i]
        image = image[:, :, ::-1]  # BGR2RGB
        io.imsave(image_path, image)


@click.command()
@click.option("--input-dir", required=True, type=click.Path(exists=True))
@click.option("--output-dir", required=True, type=click.Path())
def main(input_dir, output_dir):
    input_dir = osp.expanduser(osp.abspath(input_dir))
    output_dir = osp.expanduser(osp.abspath(output_dir))
    output_file = osp.join(output_dir, "dataset.json")
    images_dir = osp.join(output_dir, "jpg")
    corpus_file = osp.join(output_dir, "corpus-0.pth")
    input_file = osp.join(input_dir, "coco_colors.h5")
    vocab_file = osp.join(input_dir, "coco_colors_vocab.p")

    # make dirs
    if not osp.isdir(output_dir):
        os.makedirs(output_dir)
        os.makedirs(images_dir)

    # make corpus
    vocab = pickle.load(open(vocab_file, "rb"))
    vocab = sorted(vocab.items(), key=lambda x: x[1])
    corpus = Corpus()
    corpus.dictionary.add_word(PAD_TOKEN)
    for (word, _) in vocab:
        corpus.dictionary.add_word(word)
    corpus.dictionary.add_word(UNK_TOKEN)
    i2w = corpus.dictionary.idx2word
    torch.save(corpus, corpus_file)

    # create dataset file
    f = h5py.File(input_file, "r")
    trn = create_records(f, "train", i2w)
    val = create_records(f, "val", i2w)
    data = trn + val
    with open(output_file, "w") as json_file:
        json.dump(data, json_file, indent=4)

    # write images
    # write_images(f, "train", images_dir)    
    # write_images(f, "val", images_dir)    
    print("done")


if __name__ == "__main__":
    main()