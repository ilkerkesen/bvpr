#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os.path as osp

import torch
import pytorch_lightning as pl
import hydra
from omegaconf import OmegaConf
from bvpr.util import process_config
from bvpr.data.refexp import ReferDataset as Dataset
from bvpr.experiment import SegmentationExperiment as Experiment
from bvpr.datamodule import SegmentationDataModule as DataModule


CONFIG_DIR = osp.abspath(osp.join(__file__, "../..", "config"))


@hydra.main(config_path=CONFIG_DIR, config_name="generate")
def main(config):
    config = OmegaConf.to_container(config)
    config = pl.utilities.parsing.AttributeDict(config)
    pl.seed_everything(config["seed"])
    assert config["threshold"] is not None
    assert config["checkpoint"] is not None
    assert config["output"] is not None
    print(config)

    # data
    config["checkpoint"] = osp.abspath(osp.expanduser(config["checkpoint"]))
    config["trainer"]["resume_from_checkpoint"] = config["checkpoint"]
    config["trainer"]["max_epochs"] = 5000  # FIXME
    ckpt = torch.load(config["checkpoint"])
    config["model"] = ckpt["hyper_parameters"]["model"]
    train_data = Dataset(split="train", **config["dataset"])
    config["model"] = process_config(config["model"], train_data)

    # checkpoint
    experiment, datamodule = Experiment(config), DataModule(config)
    datamodule.setup(stage="test")
    trainer = pl.Trainer(
        logger=None,
        callbacks=None,
        **config["trainer"],
    )
    trainer.test(experiment, datamodule=datamodule)


if __name__ == "__main__":
    main()
